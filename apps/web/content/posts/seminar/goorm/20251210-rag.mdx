---
title: "구름 세미나 후기 - RAG 프로젝트는 왜 실패하는가?: RAG를 잘 다루고 싶은 엔지니어를 위한 패널 토크"
description: "RAG 프로젝트는 왜 실패하는가?: RAG를 잘 다루고 싶은 엔지니어를 위한 패널 토크"
date: 2025-12-10
categories: ["goorm"]
tags: ["RAG", "LLM", "AI", "seminar", "#goorm", "#langsmith"]
author: "Carefreelife98"
thumbnail: "/images/seminar/goorm/20251210-rag-post.jpg"
published: true
---

![path](/images/seminar/goorm/20251210-rag-teaser.png)

# 🎯 구름 RAG 세미나 후기 - 실무에서 마주하는 RAG의 현실

지난 12월 10일, goorm 에서 주최한 RAG 개발자 Commit 에 다녀왔습니다.
김재현님, 김태정님, 테디노트님께서 실무에서 겪은 경험을 기반으로 다양한 인사이트를 공유해주셨습니다.

---

## 💡 "정답이 없다"

세미나 내내 공감됐던 건 **"정답이 없다"** 는 말이었습니다.

특히 표나 이미지 같은 비정형 데이터를 처리할 때는 SOTA 모델을 그대로 사용하든, 자체 모델 튜닝을 하든, LangGraph 기반 파이프라인을 짜든 상황에 맞게 시도해보는 것이 최선이라는 것을 다시 한번 느꼈습니다.

다만 모든 발표자분들이 공통적으로 강조한 건 **"골든 데이터셋을 먼저 확보하라"** 는 것이었습니다.
리소스가 부족하더라도 정확도 기반의 검증 데이터가 있어야 개선 방향이 보이기에, 수작업을 해서라도 골든 데이터셋을 만들어야 하는 필요성을 느꼈습니다.

---

## 🛡️ 할루시네이션 대응

할루시네이션 대응에 대한 논의도 인상적이었습니다.

- 프롬프트를 다듬는 건 기본
- **Agentic RAG**로 validation loop 설계
- 운영 단계에서 **트레이싱**을 붙여 모니터링
- 다중 레이어로 방어하고, 할루시네이션 발생 지점을 추적

현재로서는 위와 같은 다중 레이어를 설계하여 할루시네이션 발생률을 **최대한 줄이는 방법**이 최선임을 느꼈습니다.

---

## 📄 "문서 사이의 gap을 찾아라"

특히 기억에 남는 건 이경록(테디노트)님의 **"문서 사이의 gap을 찾아라"** 라는 조언이었습니다.

> **예시**
> '마\*킴'이라는 브랜드 관련 문서가 있는 경우, 사용자가 **"MZ 세대가 좋아하는 브랜드 알려줘"** 라고 물으면 해당 문서에는 그런 표현이 없으니 검색이 되지 않습니다.
>
> 👉 **해결책**: 전처리 단계에서 "MZ 세대에게 인기 있는 브랜드"라는 컨텍스트를 메타데이터로 추가

사용자가 어떻게 질문할지를 미리 예측하고, **문서와 질문 사이의 간극을 메워주는 작업**으로 RAG 품질을 더 고도화할 수 있다는 인사이트였습니다.

---

## 📊 평가 도구: LangSmith Evaluation

평가 도구로는 이경록(테디노트)님께서 **[LangSmith Evaluation](https://docs.langchain.com/langsmith/evaluation)** 을 추천해주셨습니다.

**LangSmith Evaluation의 장점:**
- 병렬 테스트 가능
- **LLM as a Judge** 기반으로 답변 품질/어조까지 다양하게 평가

기존에는 RAG 및 LLM 응답 품질을 자체 QA 작업만으로 평가해왔는데, 결국 우리 서비스를 사용하고 평가하는 주체는 **고객**이기 때문에 자체 평가는 큰 의미가 없을 수 있다는 내용에 동감했습니다. *(+ 대표님 평가지표 😅)*

따라서:
- 자체 평가는 테스트 라이브러리와 **통일된 평가 지표**를 통해 쉽고 빠르게 수행
- 실제 고객의 피드백을 통해 더 정밀한 QA 작업 수행
- **RAGAS 평가 레이어**를 얹어 정적인 RAG 결과 분석 + LLM 기반 종합 평가 방식 검토 예정

---

## 🔤 임베딩 모델 선택

"어떤 임베딩 모델을 쓰는가"에 대해서는 크게 고민하지 않고 OpenAI Embedding 모델을 사용해왔는데, **한글 임베딩은 Qwen 계열이 OpenAI보다 성능이 압도적으로 좋다**는 내용이 인상적이었습니다.

👉 추후 RAG 관련 기능 고도화 시 **클라이언트별 동적 임베딩 모델 변경**을 고려해볼 수 있는 선택지를 얻어갈 수 있었습니다.

---

## ✨ 기타 인사이트

이외에도 다양한 문제 해결 전략에 대해 공감하며 시야를 넓힐 수 있었습니다:

- **시멘틱 캐싱**
- 청크 분리 후 후처리 단계에서 **각 청크별 예상 질문**을 메타데이터에 넣는 전략

---

## 🎯 결론

> 결국 RAG 시스템의 성공은 기술도 기술이지만, **고객과 합의된 평가 기준**에서 시작된다는 것을 다시 한번 느꼈습니다.

좋은 자리 마련해주신 goorm과 발표자분들께 감사드립니다! 🙏

---

**📌 참고 링크**

| 구분 | 링크 |
|------|------|
| 공식 정리 (구름 기술 블로그) | https://tech.goorm.io/commit/ |
| 행사 개요 및 스피커 정보 | https://tech.goorm.io/2512_commit/ |

---
